{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased estimator and consistent estimator\n",
    "\n",
    "[Back to index](https://shotahorii.github.io/math-for-ds/)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of contents\n",
    "1. **Unbiased estimator**  \n",
    "1.1. Definition  \n",
    "1.2. Examples  \n",
    "1.3. Asymptotically unbiased estimator  \n",
    "2. **Consistent Estimator**  \n",
    "2.1. Definition  \n",
    "2.2. Examples \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unbiased estimator\n",
    "### 1.1. Definition\n",
    "\n",
    "An estimator $\\hat{\\theta}$ is an unbiased estimator when following is true.\n",
    "\n",
    "$E[\\hat{\\theta}] = \\theta$\n",
    "\n",
    "Where $\\theta$ is the true parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2. Examples\n",
    "\n",
    "Assume: a set of samples $X_i$ ($i=1,2,...,n$) is i.i.d. with the true mean of $\\mu$ and the true variance of $\\sigma^2$.\n",
    "\n",
    "**Sample mean** $\\bar{X}$ : An example of unbiased estimator\n",
    "\n",
    "$\\bar{X} = \\frac{X_1+X_2+...+X_n}{n} = \\frac{1}{n}\\sum_{i=1}^nX_i$\n",
    "\n",
    "$E[\\bar{X}] = E[\\frac{1}{n}\\sum_{i=1}^nX_i] =\\frac{1}{n}\\sum_{i=1}^nE[X_i] = \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{1}{n}n\\mu = \\mu$\n",
    "\n",
    "\n",
    "**Sample variance** $S^2$ : An example of **biased** estimator\n",
    "\n",
    "$S^2 = \\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar{X})^2$\n",
    "\n",
    "$E[S^2] = E[\\frac{1}{n}\\sum_{i=1}^n(X_i-\\bar{X})^2]=\\frac{1}{n}E[\\sum_{i=1}^n(X_i-\\bar{X})^2]$\n",
    "\n",
    "$=\\frac{1}{n}E[\\sum_{i=1}^n\\{(X_i-\\mu)-(\\bar{X}-\\mu)\\}^2]$\n",
    "\n",
    "$=\\frac{1}{n}E[\\sum_{i=1}^n\\{(X_i-\\mu)^2-2(X_i-\\mu)(\\bar{X}-\\mu)+(\\bar{X}-\\mu)^2\\}]$\n",
    "\n",
    "$=\\frac{1}{n}E[\\sum_{i=1}^n(X_i-\\mu)^2-2(\\bar{X}-\\mu)\\sum_{i=1}^n(X_i-\\mu)+n(\\bar{X}-\\mu)^2]$\n",
    "\n",
    "Note: $\\sum_{i=1}^n(X_i-\\mu) = X_1+X_2+...+X_n - n\\mu = n(\\bar{X}-\\mu)$\n",
    "\n",
    "$=\\frac{1}{n}E[\\sum_{i=1}^n(X_i-\\mu)^2-2n(\\bar{X}-\\mu)^2+n(\\bar{X}-\\mu)^2]\n",
    "=\\frac{1}{n}E[\\sum_{i=1}^n(X_i-\\mu)^2-n(\\bar{X}-\\mu)^2]$\n",
    "\n",
    "$=\\frac{1}{n}\\sum_{i=1}^nE[(X_i-\\mu)^2]-E[(\\bar{X}-\\mu)^2]$\n",
    "\n",
    "Note: $E[(X_i-\\mu)^2] = E[(X_i-E[X_i])^2] = V[X_i]$\n",
    "\n",
    "Note: $E[(\\bar{X}-\\mu)^2] = E[(\\bar{X}-E[\\bar{X}])^2] = V[\\bar{X}]$\n",
    "\n",
    "$=\\frac{1}{n}\\sum_{i=1}^nV[X_i]-V[\\bar{X}]$\n",
    "\n",
    "Note: $V[X_i] = \\sigma^2$\n",
    "\n",
    "$=\\frac{1}{n}n\\sigma^2-V[\\bar{X}]=\\sigma^2-V[\\bar{X}]$\n",
    "\n",
    "Note: $V[\\bar{X}] = V[\\frac{1}{n}\\sum_{i=1}^nX_i] = \\frac{1}{n^2}V[\\sum_{i=1}^nX_i]\n",
    "= \\frac{1}{n^2}\\sum_{i=1}^nV[X_i] = \\frac{1}{n^2}n\\sigma^2 = \\frac{\\sigma^2}{n}$\n",
    "\n",
    "$=\\sigma^2-\\frac{\\sigma^2}{n} = \\frac{n-1}{n}\\sigma^2$\n",
    "\n",
    "Hence, sample variance $S^2 \\ne \\sigma^2$.\n",
    "\n",
    "**Unbiased Sample variance** $S^2$ : An example of unbiased estimator\n",
    "\n",
    "$S^2 = \\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar{X})^2$\n",
    "\n",
    "$E[S^2] = \\frac{1}{n-1}E[\\sum_{i=1}^n(X_i-\\bar{X})^2]$\n",
    "\n",
    "Note: use the calculation above.\n",
    "\n",
    "$= \\frac{1}{n-1}E[\\sum_{i=1}^n(X_i-\\mu)^2-n(\\bar{X}-\\mu)^2]$\n",
    "\n",
    "$=\\frac{1}{n-1}\\sum_{i=1}^nE[(X_i-\\mu)^2]-\\frac{n}{n-1}E[(\\bar{X}-\\mu)^2]$\n",
    "\n",
    "$=\\frac{n}{n-1}\\sigma^2-\\frac{n}{n-1}\\frac{\\sigma^2}{n}$\n",
    "\n",
    "$=\\frac{n-1}{n-1}\\sigma^2=\\sigma^2$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Asymptotically unbiased estimator\n",
    "\n",
    "As seen above, an estimator $\\hat{\\theta}$ is unbiased when $E[\\hat{\\theta}] = \\theta$. When an estimator is **biased**, the bias is calculated as below. \n",
    "\n",
    "$bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$\n",
    "\n",
    "Where $\\theta$ is the true parameter.\n",
    "\n",
    "An estimator $\\hat{\\theta}$ is an **asymptotically unbiased estimator** when following is true.\n",
    "\n",
    "$\\lim\\limits_{n \\to \\infty} bias(\\hat{\\theta}) = 0$\n",
    "\n",
    "**Example**  \n",
    "Assume: $n$ samples $X_i$ ($i=1,2,...,n$) are sampled from a continuous uniform distribution $U(0,\\theta)$.\n",
    "\n",
    "Consider an estimator $\\hat{\\theta} = max_i(X_i)$, then $E[\\hat{\\theta}] = \\frac{n}{n+1}\\theta$.\n",
    "\n",
    "Now, the bias of this estimator is below.\n",
    "\n",
    "$bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta = \\frac{n}{n+1}\\theta - \\theta = -\\frac{\\theta}{n+1}$\n",
    "\n",
    "So, this is **NOT** an unbiased estimator as $bias(\\hat{\\theta}) \\ne 0$. However, this is an asymptotically unbiased estimator as $\\lim\\limits_{n \\to \\infty} bias(\\hat{\\theta}) = 0$.\n",
    "\n",
    "**Reference**: [最大値と最小値の分布（一般論と例）](https://mathtrain.jp/orderbunpu)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Consistent estimator\n",
    "### 2.1. Definition\n",
    "\n",
    "An estimator $\\hat{\\theta}_n$ from $n$ samples is an unbiased estimator when following is true.\n",
    "\n",
    "$\\forall \\varepsilon > 0, \\lim\\limits_{n \\to \\infty}Pr(|\\hat{\\theta}_n - \\theta| < \\varepsilon) = 1$\n",
    "\n",
    "Where $\\theta$ is the true parameter.\n",
    "\n",
    "This can also be written as below.\n",
    "\n",
    "$\\forall \\varepsilon > 0, plim_{n \\to \\infty}\\hat{\\theta}_n = \\theta $\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2. Examples\n",
    "\n",
    "Assume: a set of samples $X_i$ ($i=1,2,...,n$) is i.i.d. with the true mean of $\\mu$ and the true variance of $\\sigma^2$.\n",
    "\n",
    "**Sample mean** $\\bar{X}$ : An example of consistent estimator\n",
    "\n",
    "$\\bar{X} = \\frac{X_1+X_2+...+X_n}{n} = \\frac{1}{n}\\sum_{i=1}^nX_i$\n",
    "\n",
    "$\\forall \\varepsilon > 0, \\lim\\limits_{n \\to \\infty}Pr(|\\bar{X} - \\mu| < \\varepsilon) = 1$\n",
    "\n",
    "This is exactly what Weak Law of Large Numbers tells.\n",
    "\n",
    "**An example of NOT consistent estimator**\n",
    "\n",
    "$\\hat{\\mu} = \\frac{X_1+X_n}{2}$\n",
    "\n",
    "Firstly, this estimator is an unbiased estimator, as below.\n",
    "\n",
    "$E[\\hat{\\mu}] = E[\\frac{X_1+X_n}{2}] = \\frac{1}{2}(E[X_1]+E[X_n]) = \\frac{1}{2}2\\mu = \\mu$\n",
    "\n",
    "However, this is not a consistent estimator, because...\n",
    "\n",
    "$V[\\hat{\\mu}] = V[\\frac{X_1+X_n}{2}] = \\frac{1}{4}(V[X_1]+V[X_n])=\\frac{1}{4}2\\sigma^2 = \\frac{\\sigma^2}{2}$\n",
    "\n",
    "Hence, even if we have $\\infty$ samples, variance is still not 0 as below.\n",
    "\n",
    "$\\lim\\limits_{n \\to \\infty} V[\\hat{\\mu}] = \\frac{\\sigma^2}{2}$\n",
    "\n",
    "So, \n",
    "\n",
    "$\\exists \\varepsilon > 0, \\lim\\limits_{n \\to \\infty}Pr(|\\hat{\\mu} - \\mu| < \\varepsilon) \\ne 1$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
