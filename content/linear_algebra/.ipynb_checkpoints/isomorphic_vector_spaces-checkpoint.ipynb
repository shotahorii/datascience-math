{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isomorphic vector spaces\n",
    "\n",
    "[Back to index](https://shotahorii.github.io/math-for-ds/)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of contents\n",
    "1. Definition\n",
    "2. A necessary and sufficient condition for two vector spaces to be isomorphic\n",
    "3. Why inverse matrix is only defined for square matrix? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition\n",
    "\n",
    "Two vector spaces are isomorphic if there is a mapping between them such that the mapping is bijection AND linear mapping (= an invertible linear mapping). Any such mapping is called an isomorphism.\n",
    "\n",
    "Let: $V$ and $W$ be vector spaces over the same base field $K$.\n",
    "\n",
    "An isomorphism between $V$ and $W$ is a bijection $f: V \\rightarrow W$ which respects $f(k{\\bf v}) = kf({\\bf v})$ and $f({\\bf v}+{\\bf u}) = f({\\bf v})+f({\\bf u})$ for any ${\\bf v},{\\bf u} \\in V, \\,\\, k \\in K$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Necessary and sufficient condition for two vector spaces to be isomorphic\n",
    "\n",
    "Necessary and sufficient condition for two vector spaces to be isomorphic is that the two vector spaces have **same dimension**.\n",
    "\n",
    "### Proof\n",
    "**(1)** If $V$ is a finite dimensional vector space and $dim(V)=n$, then there always be an isomorphism $f:V \\rightarrow \\mathbb{R}^n$\n",
    "\n",
    "Let basis vectors of $V$ be ${\\bf e_1}, {\\bf e_2},... ,{\\bf e_n} \\in V $\n",
    "\n",
    "Then, for any ${\\bf v} \\in V$,\n",
    "by definition of basis vectors, there always be a unique set of $a_1,a_2,...,a_n \\in \\mathbb{R}$ such that ${\\bf v} = a_1{\\bf e_1} + a_2{\\bf e_2} + ... + a_n{\\bf e_n}$.  \n",
    "In other words, for any ${\\bf v} \\in V$, there always be a corresponding $(a_1,a_2,...,a_n) \\in \\mathbb{R}^n$. Hence there's a mapping $f:V \\rightarrow \\mathbb{R}^n$. Now let's proof this mapping is an isomorphism - bijection and linear mapping.\n",
    "\n",
    "**bijection**\n",
    "\n",
    "Firstly, for any $(a_1,a_2,...,a_n) \\in \\mathbb{R}^n$, a ${\\bf v}$ always exists and $f({\\bf v}) = (a_1,a_2,...,a_n)$. Hence $f$ is a surjection.  \n",
    "Secondly, for any ${\\bf v},{\\bf w} \\in V$, if $f({\\bf v}) = (a_1,a_2,...,a_n) = f({\\bf w}) = (b_1,b_2,...,b_n)$, then $a_1 = b_1, a_2=b_2,... a_n = b_n$, which means ${\\bf v} = a_1{\\bf e_1} + a_2{\\bf e_2} + ... + a_n{\\bf e_n} = b_1{\\bf e_1} + b_2{\\bf e_2} + ... + b_n{\\bf e_n} = {\\bf w}$. Hence $f$ is an injection. Combined, $f$ is a bijection.\n",
    "\n",
    "**linear mapping**\n",
    "\n",
    "Let ${\\bf v},{\\bf w} \\in V$, and $s,t \\in \\mathbb{R}$.   \n",
    "${\\bf v} = a_1{\\bf e_1} + a_2{\\bf e_2} + ... + a_n{\\bf e_n}$  \n",
    "${\\bf w} = b_1{\\bf e_1} + b_2{\\bf e_2} + ... + b_n{\\bf e_n}$\n",
    "\n",
    "Then, $s{\\bf v} + t{\\bf w} = (sa_1+tb_1){\\bf e_1} + (sa_2+tb_2){\\bf e_2} + ... + (sa_n+tb_n){\\bf e_n}$  \n",
    "Hence $f(s{\\bf v} + t{\\bf w}) = (sa_1+tb_1,sa_2+tb_2,...,sa_n+tb_n)$  \n",
    "Also, $sf({\\bf v}) + tf({\\bf w}) = s(a_1,a_2,...,a_n)+t(b_1,b_2,...,b_n) = (sa_1+tb_1,sa_2+tb_2,...,sa_n+tb_n)$  \n",
    "So, $f(s{\\bf v} + t{\\bf w}) = sf({\\bf v}) + tf({\\bf w})$. Hence $f$ is a linear mapping.\n",
    "\n",
    "\n",
    "**(2)** If $V$ and $W$ are finite dimensional vector spaces and $dim(V)=dim(W)=n$, then there always be an isomorphism $f:V \\rightarrow W$\n",
    "\n",
    "If $V$ and $W$ are finite dimensional vector spaces and $dim(V)=dim(W)=n$, there always be isomorphisms $f:V \\rightarrow \\mathbb{R}^n$ and $g:W \\rightarrow \\mathbb{R}^n$, from the proof (1) above.\n",
    "\n",
    "Now, as $g$ is a bijection, we can make $g^{-1}:\\mathbb{R}^n\\rightarrow W$. Hence we can make $f \\circ g^{-1}:V \\rightarrow W$. As $f \\circ g^{-1}$ is a composition of linear mappings, it's also a linear mapping. Also, as $f \\circ g^{-1}$ is a composition of bijections, it's also a bijection. Proof end.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Why inverse matrix is only defined for square matrix?\n",
    "\n",
    "A $m \\times n$ matrix $A$ is a linear mapping from $n$-dimensional vector space to $m$-dimensional vector space. Now, the inverse matrix of $A$, which is $A^{-1}$, needs to be the exact inverse linear mapping of $A$. If $A{\\bf v} = {\\bf u}$ then $A^{-1}{\\bf u}$ needs to be ${\\bf v}$ (${\\bf v} \\in \\mathbb{R}^n, {\\bf u} \\in \\mathbb{R}^m$).\n",
    "\n",
    "This means, $A$ (and $A^{-1}$) needs to be an isomorphism between the vector spaces. Since the necessary and sufficient condition that an isomorphism exists is that two vector spaces have same dimension, $m$ needs to be same number (dimension) as $n$. Hence $A$ needs to be a square matrix for $A^{-1}$ to be defined. \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
